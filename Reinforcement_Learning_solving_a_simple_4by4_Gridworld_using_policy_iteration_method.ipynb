{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        # S O O O\n",
        "        # O O O *\n",
        "        # O * O O\n",
        "        # O * 0 T\n",
        "        self.actionSpace = ('U', 'D', 'L', 'R')\n",
        "        self.actions = {\n",
        "            (0, 0): ('D', 'R'),\n",
        "            (0, 1): ('L', 'D', 'R'),\n",
        "            (0, 2): ('L', 'D', 'R'),\n",
        "            (0, 3): ('L', 'D'),\n",
        "            (1, 0): ('U', 'D', 'R'),\n",
        "            (1, 1): ('U', 'L', 'D', 'R'),\n",
        "            (1, 2): ('U', 'L', 'D', 'R'),\n",
        "            (1, 3): ('U', 'L', 'D'),\n",
        "            (2, 0): ('U', 'D', 'R'),\n",
        "            (2, 1): ('U', 'L', 'D', 'R'),\n",
        "            (2, 2): ('U', 'L', 'D', 'R'),\n",
        "            (2, 3): ('U', 'L', 'D'),\n",
        "            (3, 0): ('U', 'R'),\n",
        "            (3, 1): ('U', 'L', 'R'),\n",
        "            (3, 2): ('U', 'L', 'R')\n",
        "        }\n",
        "        self.rewards = {(3, 3): 3, (1, 3): -1, (2, 1): -1, (3, 1): -1}\n",
        "        self.explored = 0\n",
        "        self.exploited = 0\n",
        "\n",
        "    def getRandomPolicy(self):\n",
        "        policy = {}\n",
        "        for state in self.actions:\n",
        "            policy[state] = np.random.choice(self.actions[state])\n",
        "        return policy\n",
        "\n",
        "    def reset(self):\n",
        "        return (0, 0)\n",
        "        \n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def getNewState(self,state,action):\n",
        "      i, j = zip(state)\n",
        "      row = int(i[0])\n",
        "      column = int(j[0])\n",
        "      if action == 'U':\n",
        "          row -= 1\n",
        "      elif action == 'D':\n",
        "          row += 1\n",
        "      elif action == 'L':\n",
        "          column -= 1\n",
        "      elif action == 'R':\n",
        "          column += 1\n",
        "      return row,column\n",
        "\n",
        "    def chooseAction(self, state, policy, exploreRate):\n",
        "        if exploreRate > np.random.rand():\n",
        "            self.explored += 1\n",
        "            return np.random.choice(self.actions[state])\n",
        "        self.exploited += 1\n",
        "        return policy[state]\n",
        "\n",
        "    def greedyChoose(self, state, values):\n",
        "        actions = self.actions[state]\n",
        "        stateValues = []\n",
        "        for act in actions:\n",
        "            row,column=self.getNewState(state,act)\n",
        "            if (row, column) in values:\n",
        "                stateValues.append(values[(row, column)])\n",
        "        return actions[np.argmax(stateValues)]\n",
        "    \n",
        "    def move(self, state, policy, exploreRate):\n",
        "        action = self.chooseAction(state, policy, exploreRate)\n",
        "        row,column=self.getNewState(state,action)\n",
        "        if (row, column) in self.rewards:\n",
        "            return (row, column),self.rewards[(row, column)]\n",
        "        return (row, column), 0\n",
        "\n",
        "    def printVaues(self,values):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in values:\n",
        "            line += f\" | {values[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"--------------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")\n",
        "        \n",
        "    def printPolicy(self, policy):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in policy:\n",
        "            line += f\" | {policy[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"----------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")\n",
        "        "
      ],
      "metadata": {
        "id": "_gVBm7gDHgUt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enviroment = GridWorld()\n",
        "policy = enviroment.getRandomPolicy()\n",
        "# enviroment.printPolicy(policy)\n",
        "\n",
        "#example optimal policy = {(0, 0): 'R', (0, 1): 'R', (0, 2): 'D', (0, 3): 'D', (1, 0): 'R', (1, 1): 'D', (1, 2): 'D', (1, 3): 'D',\n",
        "#           (2, 0): 'R', (2, 1): 'D', (2, 2): 'R', (2, 3): 'D', (3, 0): 'R', (3, 1): 'R', (3, 2): 'R'}\n",
        "\n",
        "for i in range(51):\n",
        "  values = {}\n",
        "  for state in policy:\n",
        "      values[state] = 0\n",
        "  values[(3, 3)] = 5\n",
        "\n",
        "  for j in range(50):\n",
        "    state = enviroment.reset()\n",
        "    while not enviroment.is_terminal(state):# and can add for example terminal condition after 20steps\n",
        "      nextState, reward = enviroment.move(state, policy, exploreRate=0.05)\n",
        "      values[state] = reward + 0.1 * values[nextState]\n",
        "      state=nextState\n",
        "  for item in policy:\n",
        "        policy[item] = enviroment.greedyChoose(item, values)\n",
        "  \n",
        "  if (i%10)==0:\n",
        "    print(f\"\\n\\n\\n step:{i}\")\n",
        "    # enviroment.printVaues(values)\n",
        "    enviroment.printPolicy(policy)\n",
        "\n",
        "print(f\"exploited:{enviroment.exploited}  explored:{enviroment.explored}\")"
      ],
      "metadata": {
        "id": "yma4qfqfHkga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b52ff7-60c5-4411-a941-a17f2b46a971"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            " step:0\n",
            " | R |  | L |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:10\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:20\n",
            " | R |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:30\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:40\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:50\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "exploited:255995  explored:13453\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Reinforcement-Learning-solving-a-simple-4by4-Gridworld-using-policy-iteration-method",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
